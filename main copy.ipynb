{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nis\\AppData\\Local\\Temp\\ipykernel_10064\\830576611.py:22: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-whitegrid')\n"
     ]
    }
   ],
   "source": [
    "# Standard imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# OS and time packages \n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import datetime\n",
    "\n",
    "# HTML and text processing \n",
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Plotting \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc('font', size=14)             # controls default text sizes\n",
    "plt.rc('axes', titlesize=18)        # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=18)        # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=14)       # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14)       # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=14)       # legend fontsize\n",
    "plt.rc('figure', titlesize=20)      # fontsize of the figure title\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 4 # set default size of plots\n",
    "\n",
    "# Filter warnings \n",
    "pd.options.mode.chained_assignment = None\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(response: requests.Response):\n",
    "    \"\"\"\n",
    "    Creates or appends a log-file with information from a `requests.get()`-call.\n",
    "    \n",
    "    The information gathered is:\n",
    "    - - - - - - - -\n",
    "        timestamp   :   Current local time.\n",
    "        status_code :   Status code from requests call.\n",
    "        length      :   Length of the HTML-string.\n",
    "        output_path :   Current working directory.\n",
    "        url         :   The URL of the response.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open or create the csv file\n",
    "    if os.path.isfile('log'):\n",
    "        log = open('log','a')\n",
    "    else: \n",
    "        log = open('log','w')\n",
    "        header = ['timestamp', 'status_code', 'length', 'output_file', 'url'] # Header names\n",
    "        log.write(';'.join(header) + \"\\n\")\n",
    "        \n",
    "    # Gather log information\n",
    "    status_code = response.status_code # Status code from the request result\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) # Local time\n",
    "    length = len(response.text) # Length of the HTML-string\n",
    "    output_path = os.getcwd() # Output path\n",
    "    url = response.url # URL-string\n",
    "    \n",
    "    # Open the log file and append the gathered log information\n",
    "    with open('log','a') as log:\n",
    "        log.write(f'{timestamp};{status_code};{length};{output_path};{url}' + \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url: str, header: dict) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Constructs a HTML-string from a request of the given URL. \n",
    "    Requests are logged, see `log()`. \n",
    "\n",
    "    Input:\n",
    "    - - - - - - - - \n",
    "    url (str)     :    URL of the website to receive the HTML-string from. \\n\n",
    "    header (dict) :    Dictionary to send in the query string for the request.\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - - \n",
    "    soup (BeautifulSoup) :  HTML-string in the class of BeutifulSoup with 'lxml' parser.\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(url, headers=header) # Request\n",
    "    log(response) # Log \n",
    "    soup = BeautifulSoup(response.content, 'lxml') # Convert to response to HTML\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url_boliga(page: int) -> str:\n",
    "    \"\"\"\n",
    "    Creates a boliga URL with the given pagenumber.\n",
    "\n",
    "    Input:\n",
    "    - - - - - - - -\n",
    "    page (int) :    Pagenumber for the boliga website.\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - -\n",
    "    url (str)  :    URL of the boliga website for given page. \n",
    "    \"\"\"\n",
    "\n",
    "    url = f'https://www.boliga.dk/salg/resultater?searchTab=1&page={page}&sort=date-a' # Construct url with f-string\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'name' : 'Jørgen Baun Høst',          'email' : 'pjz633@econ.ku.dk',\n",
    "          'intention': 'Scrape Boliga for academic purposes'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_boliga(soup:BeautifulSoup) -> pd.DataFrame:\n",
    "        \n",
    "    href = soup.find(class_=\"text-primary font-weight-bolder text-left\")['href']\n",
    "    url = f'https://www.boliga.dk{href}'\n",
    "    id = re.search(r'[^/]+$', href)[0]\n",
    "    url_bbr = f'https://www.boliga.dk/bbrinfo/{id}'\n",
    "    address = soup.find(class_=\"text-primary font-weight-bolder text-left\").text\n",
    "    price = soup.find(class_=\"table-col d-print-table-cell text-center\").text\n",
    "    date_of_sale = soup.div.find_all('span')[0].text\n",
    "    type_of_sale = soup.div.find_all('span')[1].text\n",
    "    house_size = soup.find(class_='d-flex flex-column').find_all('span')[0].text\n",
    "    price_per_m2 = soup.find(class_='d-flex flex-column').find_all('span')[1].text\n",
    "    no_of_rooms = soup.find_all('td')[4].text\n",
    "    year_built = soup.find_all('td')[5].text\n",
    "\n",
    "    return [url, url_bbr, address, price, date_of_sale, type_of_sale, house_size, price_per_m2, no_of_rooms, year_built]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['link', 'bbr_link', 'address', 'price', 'date_of_sale','type_of_sale', 'house_size_m2', 'house_price_per_m2', 'no_of_rooms', 'year_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [40:27<00:00,  3.47s/it]\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "\n",
    "startpage = 13501\n",
    "endpage = 14200\n",
    "\n",
    "for page in tqdm.tqdm(range(startpage, endpage+1)):\n",
    "    url = create_url_boliga(page)\n",
    "    try:\n",
    "        soup = get_soup(url, header)\n",
    "        list_of_ads = soup.find_all('tr')\n",
    "\n",
    "        output = []\n",
    "\n",
    "        for ad in list_of_ads:\n",
    "            info = extract_info_boliga(ad)\n",
    "            output.append(info)\n",
    "\n",
    "        df = pd.DataFrame(output, columns=column_names)\n",
    "        df.to_parquet(f'data/frontpage/boliga_{page}.pq')\n",
    "        time.sleep(0.1)\n",
    "    except: #skip page if errors\n",
    "        print(f'Error encountered on page {page}')\n",
    "        errors.append(url)\n",
    "        df_error = pd.DataFrame(errors).to_csv('errors.csv')\n",
    "        time.sleep(0.1)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
