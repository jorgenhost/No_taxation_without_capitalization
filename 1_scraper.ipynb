{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toolbox\n",
    "import tools as tools\n",
    "\n",
    "# Standard imports \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# OS and time packages \n",
    "import time\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "import concurrent.futures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Fetch meta data](#toc1_)    \n",
    "  - [Make list of urls to webscrape](#toc1_1_)    \n",
    "  - [Merge and clean data from Boliga](#toc1_2_)    \n",
    "  - [Read BBR urls to scrape](#toc1_3_)    \n",
    "- [Webscrape BBR data from boliga.dk](#toc2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Header (state non-commercial/academic intentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'name' : 'Jørgen Baun Høst',          'email' : 'pjz633@econ.ku.dk',\n",
    "          'intention': 'Scrape Boliga for academic purposes'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Fetch meta data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pageIndex': 1,\n",
       " 'pageSize': 2000,\n",
       " 'totalCount': 441678,\n",
       " 'totalPages': 221,\n",
       " 'minPage': 1,\n",
       " 'maxPage': 6,\n",
       " 'countFrom': 1,\n",
       " 'countTo': 2000}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.boliga.dk/api/v2/sold/search/results?pageSize=2000&page=1&salesDateMin=2000&salesDateMax=2008&propertytype=1&saleType=1&sort=date-d&buildYearMax=2005'\n",
    "bbr_test_url = 'https://api.boliga.dk/api/v2/bbrinfo/bbr?id=69cd6d3d-e858-43aa-b530-bd20f132e3b8'\n",
    "output=tools.get_json(url=url, header=header)\n",
    "output['meta']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Make list of urls to webscrape](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_url = []\n",
    "\n",
    "total_pages = output['meta']['totalPages']\n",
    "\n",
    "for page in range(1, total_pages+1):\n",
    "    url = f'https://api.boliga.dk/api/v2/sold/search/results?pageSize=2000&page={page}&salesDateMin=2000&salesDateMax=2008&propertytype=1&saleType=1&sort=date-d&buildYearMax=2005'\n",
    "    list_of_url.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396/396 [04:28<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "\n",
    "def process_url(id_url_pair):\n",
    "    id_, url = id_url_pair\n",
    "    try:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # Get the JSON file\n",
    "        out = tools.get_json(url, header)\n",
    "\n",
    "        # Make pd.DataFrame\n",
    "        df = pd.DataFrame(out['results'])\n",
    "\n",
    "        # Select numeric cols: i) Floats ii) Integers\n",
    "        fcols = df.select_dtypes('float').columns\n",
    "        icols = df.select_dtypes('integer').columns\n",
    "        \n",
    "        # Downcast to most optimal dtype to conserve memory\n",
    "        df[fcols] = df[fcols].apply(pd.to_numeric, downcast='float')\n",
    "        df[icols] = df[icols].apply(pd.to_numeric, downcast='integer')\n",
    "\n",
    "        # Save in data folder\n",
    "        return df.to_parquet(f'data/boliga/boliga_{id_}.pq')\n",
    "    except:\n",
    "        print(f'Error encountered on url {url}')\n",
    "        errors.append(url)\n",
    "        pd.DataFrame(errors).to_csv\n",
    "        return id_, None\n",
    "\n",
    "id_url_pairs = [(id_, url) for id_, url in enumerate(list_of_url)]\n",
    "\n",
    "## NB! Do not overload Boliga's servers - scrape at odd hours and/or adjust max_workers accordingly!\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    results = list(tqdm.tqdm(executor.map(process_url, id_url_pairs), total=len(id_url_pairs)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Merge and clean data from Boliga](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('data/boliga')\n",
    "full_df1 = pd.concat(\n",
    "    pd.DataFrame(pd.read_parquet(pq_file))\n",
    "    for pq_file in data_dir.glob('*.pq')\n",
    ")\n",
    "\n",
    "df=full_df1.reset_index(drop=True)\n",
    "df['soldDate']=pd.to_datetime(df['soldDate'])\n",
    "df['year']=df.soldDate.dt.year\n",
    "df['month']=df.soldDate.dt.month\n",
    "df['week']=df.soldDate.dt.weekday\n",
    "df['time_q']=pd.PeriodIndex(df['soldDate'], freq='Q')\n",
    "\n",
    "df=df.drop(columns=['change'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Read BBR urls to scrape](#toc0_)\n",
    "\n",
    "Some houses are sold more than once in the period..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_bbr_urls = []\n",
    "list_of_guids = list(df['guid'].unique())\n",
    "\n",
    "for i,guid in enumerate(list_of_guids):\n",
    "    bbr_url = f'https://api.boliga.dk/api/v2/bbrinfo/bbr?id={guid}'\n",
    "    list_of_bbr_urls.append(bbr_url)\n",
    "\n",
    "pd.DataFrame(list_of_bbr_urls, columns=['bbr_url']).to_parquet('data/bbr_ids_scraper.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519604"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temp_df = pd.read_parquet('data/bbr_ids_scraper.pq')\n",
    "list_of_bbr_urls = list(temp_df['bbr_url'])\n",
    "len(list_of_bbr_urls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Webscrape BBR data from boliga.dk](#toc0_)\n",
    "NB! Will take a lot of time to run. Took me about 24 hrs on an 8-core, 16gb RAM laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.76it/s]\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "\n",
    "def process_url(id_url_pair):\n",
    "    id_, url = id_url_pair\n",
    "    try:\n",
    "        time.sleep(0.5)\n",
    "        # Get the JSON file\n",
    "        out = tools.get_json(url, header)\n",
    "\n",
    "        # Normalize/flatten JSON-file\n",
    "        json_dat=pd.json_normalize(out)[\n",
    "            ['unitId','evaluationInfos','bbrInfoBox.lotSize', 'bbrInfoBox.area', 'bbrInfoBox.evaluationPrice', 'unitInfo.toiletQuantity','unitInfo.bathroomQuantity','unitInfo.propertyUnitType','bfenr']\n",
    "            ]\n",
    "\n",
    "        # Make pd.DataFrame\n",
    "        df = pd.DataFrame(json_dat)\n",
    "\n",
    "        # Select numeric cols: i) Floats ii) Integers\n",
    "        fcols = df.select_dtypes('float').columns\n",
    "        icols = df.select_dtypes('integer').columns\n",
    "        \n",
    "        # Downcast to most optimal dtype to conserve memory\n",
    "        df[fcols] = df[fcols].apply(pd.to_numeric, downcast='float')\n",
    "        df[icols] = df[icols].apply(pd.to_numeric, downcast='integer')\n",
    "\n",
    "        # Save in data folder\n",
    "        return df.to_parquet(f'data/bbr/bbr_{id_}.pq')\n",
    "\n",
    "    except:\n",
    "        print(f'Error encountered on url {url}')\n",
    "        errors.append(url)\n",
    "        pd.DataFrame(errors).to_csv\n",
    "        return id_, None\n",
    "\n",
    "id_url_pairs = [(id_, url) for id_, url in enumerate(list_of_bbr_urls)]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    results = list(tqdm.tqdm(executor.map(process_url, id_url_pairs), total=len(id_url_pairs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
